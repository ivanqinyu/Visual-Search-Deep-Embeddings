{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import pandas\n",
    "import random\n",
    "# import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from  PIL import Image\n",
    "from time import time\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "resnet= models.resnet152(pretrained=True)\n",
    "# resnet = models.resnet152(pretrained=True)\n",
    "# freeze all base layers; Parameters of newly constructed modules have requires_grad=True by default\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "num_ftrs = resnet.fc.in_features\n",
    "\n",
    "\n",
    "\n",
    "print(num_ftrs)\n",
    "# resnet = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(torch.nn.Module):\n",
    "    def init(self):\n",
    "        super(Identity, self).init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "resnet.fc = Identity() # Remove the prediction head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, end, as_tensor = False):\n",
    "        \n",
    "    images = []\n",
    "    num_img = []\n",
    "    file_count= 0\n",
    "    dirnames = [] \n",
    "\n",
    "\n",
    "    for _, dirnames, filenames in os.walk(folder):\n",
    "\n",
    "        if dirnames != []:\n",
    "            subfolders = dirnames\n",
    "        current_path = os.path.join(folder, subfolders[file_count])\n",
    "        num_img.append(len(os.listdir(current_path)))\n",
    "        for filename in os.listdir(current_path):\n",
    "                if as_tensor:\n",
    "                    img = cv2.imread(os.path.join(current_path, filename))\n",
    "                    if img is not None:    \n",
    "                        img = torch.from_numpy(img).type(torch.uint8)               \n",
    "                        images.append(img)\n",
    "                        \n",
    "                else:\n",
    "                    img = Image.open(os.path.join(current_path, filename))\n",
    "                    if img is not None:    \n",
    "                        images.append(img)\n",
    "\n",
    " \n",
    "\n",
    "        file_count += 1\n",
    "        \n",
    "        if file_count % 10 == 0:\n",
    "            print('number of folder done =', file_count, 'total number of images so far =', len(images))\n",
    "            \n",
    "        if file_count  == end:\n",
    "            return images, num_img\n",
    "\n",
    "    return images, num_img\n",
    "\n",
    "\n",
    "def show_image(PIL_img):\n",
    "    plt.figure()\n",
    "    plt.imshow(PIL_img)\n",
    "#     PIL_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy()\n",
    "    inp.transpose((0, 2, 1))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "def show_tensor_image(image_tensor, preprocess = False):\n",
    "    # use this code when showing the images\n",
    "    inp = image_tensor.numpy()\n",
    "    if preprocess:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "\n",
    "    im2 = inp.copy()\n",
    "    im2[:, :, 0] = image_tensor[:, :, 2]\n",
    "    im2[:, :, 2] = image_tensor[:, :, 0]\n",
    "    plt.imshow(im2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path where the folder is\n",
    "path ='../uob_image_set'\n",
    "\n",
    "N_CHANNELS = 3\n",
    "\n",
    "images, num_images = load_images_from_folder(path, 100, as_tensor= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the mean and std values form the ImageNet data for which it was pretrained\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_batch(image_list):\n",
    "    list_input_tensor = []\n",
    "    list_input_batch = []\n",
    "    \n",
    "    for item in range(len(image_list)):\n",
    "        input_tensor = preprocess(image_list[item])\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "        list_input_tensor.append(input_tensor)\n",
    "        list_input_batch.append(input_batch)\n",
    "    return list_input_batch, list_input_tensor\n",
    "\n",
    "list_input_batch, list_input_tensor= preprocess_and_batch(images)\n",
    "print(list_input_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def feed_batch_to_network(list_input_batch, network):\n",
    "    output_array = []\n",
    "    for i in range(len(list_input_batch)):\n",
    "        if torch.cuda.is_available():\n",
    "            input_batch = list_input_batch[i].to('cuda')\n",
    "            resnet.to('cuda')\n",
    "        else:\n",
    "            input_batch = list_input_batch[i].to('cpu')\n",
    "            resnet.to('cpu')\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            output = network(input_batch)\n",
    "            cpu_tensor = output.cpu()\n",
    "            pos = cpu_tensor[0].tolist()       \n",
    "            output_array.append(pos)\n",
    "    output_array = np.asarray(output_array)\n",
    "    return output_array\n",
    "\n",
    "network_output = feed_batch_to_network(list_input_batch, resnet)\n",
    "print(network_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def output_3d_plot(num_images):\n",
    "\n",
    "#     fig = plt.figure()\n",
    "#     ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "#     img_counter = 0\n",
    "#     for n in num_images:\n",
    "#         r = lambda: random.randint(0,255)\n",
    "#         random_color = '#%02X%02X%02X' % (r(),r(),r())\n",
    "#         ax.scatter(network_output[img_counter:img_counter + n,0], network_output[img_counter:img_counter + n,1], network_output[img_counter:img_counter + n,2],color=random_color,s=20)\n",
    "#         img_counter += n\n",
    "\n",
    "\n",
    "#     ax.set_xlabel('X Axes')\n",
    "#     ax.set_ylabel('Y Axes')\n",
    "#     ax.set_zlabel('Frame Axes')\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def output_2d_plot(network_output,num_images, dimension_1, dimension_2):\n",
    "#     # dimension numbers = 0, 1, 2\n",
    "#     fig = plt.figure()\n",
    "#     img_counter = 0\n",
    "#     for n in num_images:\n",
    "#         r = lambda: random.randint(0,255)\n",
    "#         random_color = '#%02X%02X%02X' % (r(),r(),r())\n",
    "#         plt.plot(network_output[img_counter:img_counter + n,dimension_1],network_output[img_counter:img_counter + n,dimension_2], 'o',color=random_color)\n",
    "#         img_counter += n\n",
    "#     plt.xlabel(\"dimension1\")\n",
    "#     plt.ylabel(\"dimension2\")\n",
    "#     plt.show()            \n",
    "# # output_2d_plot(network_output,num_images, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_data = preprocessing.scale(network_output)\n",
    "# pca = PCA()\n",
    "# pca.fit(scaled_data)\n",
    "# pca_data = pca.transform(scaled_data)\n",
    "# per_var = np.round(pca.explained_variance_ratio_*100, decimals = 1)\n",
    "# per_var\n",
    "\n",
    "# labels = ['PC' +  str(x) for x in range(1,len(per_var)+1)]\n",
    "# plt.bar(x=range(1,len(per_var)+1), height=per_var)\n",
    "# plt.xlabel(\"principal components\")\n",
    "# plt.ylabel(\"explained variannce\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pca_df = pd.DataFrame(pca_data, columns=labels)\n",
    "\n",
    "# def pca_2d_plot(pca_df, num_images, dimension_1, dimension_2):\n",
    "#     fig = plt.figure()\n",
    "#     img_counter = 0\n",
    "#     for n in num_images:\n",
    "#         r = lambda: random.randint(0,255)\n",
    "#         random_color = '#%02X%02X%02X' % (r(),r(),r())\n",
    "#         plt.plot(dimension_1[img_counter:img_counter + n], dimension_2[img_counter:img_counter + n], 'o',color=random_color)\n",
    "#         img_counter += n\n",
    "#     plt.xlabel(\"dimension1\")\n",
    "#     plt.ylabel(\"dimension2\")\n",
    "#     plt.show()\n",
    "# pca_2d_plot(pca_df, num_images, pca_df.PC1,  pca_df.PC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-a44dec71084a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnetwork_output\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "len(network_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_simllar_images(img_target, network_output, show_img = False):\n",
    "    equidian_difference_list = []\n",
    "    for images in network_output:\n",
    "        equidian_difference = np.linalg.norm(img_target - images)\n",
    "        equidian_difference_list.append(equidian_difference)\n",
    "    equidian_difference_array = np.array(equidian_difference_list)\n",
    "    sort_index = np.argsort(equidian_difference_array)\n",
    "    \n",
    "    return sort_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_order, equidian_difference_sort = display_simllar_images(network_output[6], network_output, show_img=True)\n",
    "print(equidian_difference_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " def show_similar_img(images_order, number_similar_img):\n",
    "    fig = plt.figure()\n",
    "    for i in range(0,number_similar_img):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(images[images_order[i]])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_order = display_simllar_images(network_output[53], network_output, show_img=True)\n",
    "# images_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_similar_img(images_order, number_similar_img=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_path_list(path, lim):\n",
    "    all_paths = []\n",
    "    folders = os.listdir(path)\n",
    "    for folder in folders:\n",
    "        path_folder = os.path.join(path,folder)\n",
    "        inside = os.listdir(path_folder)\n",
    "        inside = [i.split(\".\")[0] for i in inside]\n",
    "        all_paths.extend(inside)\n",
    "        \n",
    "        if len(all_paths) >= lim:\n",
    "            return all_paths\n",
    "        \n",
    "    \n",
    "    return all_paths\n",
    "\n",
    "all_paths = get_path_list(path, sum(num_images))\n",
    "all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_diff_matrix(embeddings, image_names):\n",
    "    n = len(image_names)\n",
    "    emb_diff = dict([(name, {}) for name in image_names])\n",
    "    matrix = np.zeros((n,n))\n",
    "\n",
    "    print()\n",
    "    print(\"Calculating Diffs...\")\n",
    "    for i in tqdm(range(0, n)):\n",
    "        folder_name = image_names[i].split(\"_\")[0]\n",
    "        for j in range(0, i):\n",
    "            comparison_name = image_names[j].split(\"_\")[0]\n",
    "            if folder_name != comparison_name:\n",
    "                emb_1 = embeddings[i]\n",
    "                emb_1_name = image_names[i]\n",
    "                emb_2 = embeddings[j]\n",
    "                emb_2_name = image_names[j]\n",
    "\n",
    "\n",
    "                diff = np.linalg.norm(emb_1 - emb_2)\n",
    "                emb_diff[emb_1_name][emb_2_name] = diff\n",
    "                emb_diff[emb_2_name][emb_1_name] = diff\n",
    "                matrix[i][j] = diff\n",
    "                matrix[j][i] = diff\n",
    "\n",
    "\n",
    "    return emb_diff, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_dict, matrix = get_diff_matrix(network_output,all_paths )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(diff_dict.keys())[-1]\n",
    "k, k in diff_dict[k].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"error_net_diff.npy\", diff_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_weighted_triplet(list_euc, exp_sing):\n",
    "    exponetial_list = []\n",
    "    for i in list_euc:\n",
    "        exponetial = np.exp(exp_sing*i)\n",
    "        exponetial_list.append(exponetial)\n",
    "\n",
    "    batch_weighted_triplet_list =[]\n",
    "    sum_exp = sum(exponetial_list)\n",
    "    for e in exponetial_list:\n",
    "        weighted_triplet = e/sum_exp\n",
    "        batch_weighted_triplet_list.append(weighted_triplet)\n",
    "    return batch_weighted_triplet_list\n",
    "\n",
    "def batch_weighted_triplet_positive(list_euc):\n",
    "    exp_sing = 1\n",
    "    return find_weighted_triplet(list_euc, exp_sing)\n",
    "\n",
    "\n",
    "def batch_weighted_triplet_negative(list_euc):\n",
    "    exp_sing = -1\n",
    "    return find_weighted_triplet(list_euc, exp_sing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_order[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weighted_triplet_negative = batch_weighted_triplet_negative(equidian_difference_sort[1:11])\n",
    "weighted_triplet_negative"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random.choices(images_order[1:11], weighted_triplet_negative)\n",
    "\n",
    "\n",
    "# dimensions =3\n",
    "# n = sum(num_images)    # number of vectors                   \n",
    "\n",
    "# def shuffle_vectors(num_vectors, vector_dimension):\n",
    "#     np.random.seed(1)  \n",
    "#     # random shuffle of vectors          \n",
    "#     db_vectors = np.random.random((num_vectors, vector_dimension)).astype('float32')\n",
    "#     return db_vectors\n",
    "# db_vectors = shuffle_vectors(n,dimensions)\n",
    "\n",
    "# def index_vector_space(num_clusters, vector_dimension):\n",
    "#     # to assign the vectors to a particular cluster. This is usually another index that uses the L2 distance metric (we use the FlatL2 index)\n",
    "#     quantiser = faiss.IndexFlatL2(vector_dimension)  \n",
    "#     index = faiss.IndexIVFFlat(quantiser, vector_dimension, num_clusters,   faiss.METRIC_L2)\n",
    "\n",
    "#     return quantiser, index\n",
    "\n",
    "# quantiser, index = index_vector_space(8, dimensions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_index(index, expected_num_images = None):\n",
    "#     # TODO make sure index is not already trained\n",
    "#     if index.is_trained:\n",
    "#         return print(\"index has been trained\")\n",
    "#     index.train(db_vectors)  # train on the database vectors\n",
    "#     print(index.ntotal)   # 0\n",
    "#     index.add(db_vectors)   # add the vectors and update the index\n",
    "#     print(index.is_trained)  # True\n",
    "#     print(index.ntotal)   # number of images\n",
    "#     print(\"equal\", len(images) == index.ntotal)\n",
    "#     if expected_num_images is not None:\n",
    "#         assert index.ntotal == expected_num_images, \"index total does not match expected number of images\"\n",
    "\n",
    "# train_index(index, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def search_n_clusters(index, num_clusters, num_search_results, vector_dimension, num_query_vec = 1,):\n",
    "#     nprobe = num_clusters  # nprobe parameter specifies the number of clusters to visit during the search operation (nprobe<nlist). hyper-parameter which can be tuned         for different results\n",
    "#     n_query = num_query_vec\n",
    "#     # ‘k’ specifies the number of similar vectors to be returned from the visited clusters.\n",
    "#     k = num_search_results  # return 3 nearest neighbours\n",
    "\n",
    "#     np.random.seed(0)   \n",
    "#     query_vectors = np.random.random((n_query, vector_dimension)).astype('float32')\n",
    "#     print(query_vectors)\n",
    "#     #  search operation will return the ids (row numbers or index in the vector store) of the k most similar vectors for each query vector along with their respective          distances\n",
    "#     distances, indices = index.search(query_vectors, k)\n",
    "\n",
    "#     return distances, indices\n",
    "\n",
    "\n",
    "# distances, indices = search_n_clusters(index, 8,15,\n",
    "# dimensions,num_query_vec = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "5d83d67c5c4ad5bf9f8eccbea9629866ba62f30ed11b57974aec01afaaea31ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}