{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from PIL import Image, ImageStat\n",
    "from torchvision.transforms import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "h,w = 134,100\n",
    "# h,w = 1333, 1000\n",
    "transform = transforms.Resize((h,w))\n",
    "images_path = 'D:\\My Docs/University\\Applied Data Science\\Project/uob_image_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def full_path(dir_name):\n",
    "    image_folder = os.path.join(images_path, dir_name)\n",
    "\n",
    "    img_name = os.listdir(image_folder)[0]\n",
    "    return os.path.join(image_folder, img_name)\n",
    "\n",
    "\n",
    "def get_images():\n",
    "    chosen = os.listdir(images_path)\n",
    "\n",
    "    imgs = [Image.open(full_path(k)) for k in tqdm(chosen)]\n",
    "    imgs = [transform(i) for i in tqdm(imgs)]\n",
    "    print(\"LOADED\")\n",
    "    return np.array(imgs)\n",
    "\n",
    "def get_fft(img):\n",
    "\n",
    "    gray = np.array(img.convert(\"LA\"))\n",
    "    dft = cv2.dft(np.float32(gray), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "    magnitude_spectrum = 20 * np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))\n",
    "    return magnitude_spectrum\n",
    "\n",
    "def get_closest(images, fft_diff, idx, k):\n",
    "    images = np.array(images)\n",
    "    row = fft_diff[idx]\n",
    "    k_smallest_idx = np.argsort(row)[1:k+1]\n",
    "    return images[k_smallest_idx]\n",
    "\n",
    "def showImages(images, h = h):\n",
    "\n",
    "    dst = Image.new('RGB', (len(images) * w, h))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for i in images:\n",
    "        dst.paste(i, (x,y))\n",
    "        x+= w\n",
    "\n",
    "    dst.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def get_fourier_matrix(images):\n",
    "    fft_images = [get_fft(i) for i in tqdm(images)]\n",
    "    n = len(images)\n",
    "    fft_diff = np.zeros((n,n))\n",
    "\n",
    "    for i in tqdm(range(0, n)):\n",
    "        for j in range(0, i):\n",
    "\n",
    "            if i != j:\n",
    "                fft_1 = fft_images[i]\n",
    "                fft_2 = fft_images[j]\n",
    "\n",
    "                diff = np.sum(abs(fft_1 - fft_2))\n",
    "                fft_diff[i][j] = diff\n",
    "                fft_diff[j][i] = diff\n",
    "\n",
    "    return fft_diff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def get_col(image):\n",
    "    centre =  transforms.CenterCrop((30, 30))\n",
    "    cropped = centre(image)\n",
    "    return ImageStat.Stat(cropped).median\n",
    "\n",
    "def get_colour_matrix(images):\n",
    "    col_images = [get_col(i) for i in tqdm(images)]\n",
    "    n = len(images)\n",
    "    col_diff = np.zeros((n,n))\n",
    "\n",
    "    for i in tqdm(range(0, n)):\n",
    "        for j in range(0, i):\n",
    "\n",
    "            if i != j:\n",
    "                col_1 = np.array(col_images[i])\n",
    "                col_2 = np.array(col_images[j])\n",
    "\n",
    "                diff = np.sum(abs(col_1 - col_2))\n",
    "                col_diff[i][j] = diff\n",
    "                col_diff[j][i] = diff\n",
    "\n",
    "    return col_diff\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10720b1989834f85bfa2abd233968992"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fd37dc7ce7546848d7416743a64232d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-b8e3e7fcf983>:14: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(imgs)\n",
      "<ipython-input-64-b8e3e7fcf983>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(imgs)\n"
     ]
    }
   ],
   "source": [
    "images = get_images()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "639afe66cc8048eab50db8e27ff1ea26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08c943809a68448091b9ea1167515c18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc03af6fb998498f9f05ef1279d30149"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db38be307e0543718488c27479527ff7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fft_diff_matrix = get_fourier_matrix(images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0ed48b69e7a4c019301f525bbd8da5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eeef32c9c6bc40999368542ae1a358be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_diff_matrix = get_colour_matrix(images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "def get_measures(w_matrix):\n",
    "    w_matrix = w_matrix.flatten()\n",
    "    above_zero_idxs = np.where(w_matrix > 0)\n",
    "    above_zero = w_matrix[above_zero_idxs]\n",
    "    min_w = np.amin(above_zero)\n",
    "    max_w = np.amax(above_zero)\n",
    "    average = np.mean(above_zero)\n",
    "    # variance = np.var(above_zero)\n",
    "    measures = [min_w, max_w, average]\n",
    "    return measures\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def get_error_matrix(fft_diff_matrix, col_diff_matrix):\n",
    "    fft_min, fft_max, fft_mean = get_measures(fft_diff_matrix)\n",
    "    col_min, col_max, col_mean = get_measures(col_diff_matrix)\n",
    "    transformed_fft = (fft_diff_matrix - fft_min) / (fft_max - fft_min)\n",
    "    transformed_col = (col_diff_matrix - col_min) / (col_max - col_min)\n",
    "    col_measures = get_measures(transformed_col)\n",
    "    fft_measures = get_measures(transformed_fft)\n",
    "    scaler = col_measures[2] / fft_measures[2]\n",
    "    error_matrix =  scaler * transformed_fft + transformed_col\n",
    "    return error_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def add_colour_below(images):\n",
    "    joint_images = []\n",
    "\n",
    "    for im in images:\n",
    "        w,h = im.size\n",
    "        mode_col = tuple(get_col(im))\n",
    "        col_img = Image.new('RGB', (w, h), mode_col)\n",
    "        dst = Image.new('RGB', (w, 2 * h))\n",
    "        dst.paste(im, (0, 0))\n",
    "        dst.paste(col_img, (0, im.height))\n",
    "        joint_images.append(dst)\n",
    "\n",
    "    return joint_images\n",
    "\n",
    "\n",
    "def show_example():\n",
    "    error_matrix = get_error_matrix(fft_diff_matrix, col_diff_matrix)\n",
    "    idx = random.randint(0, 1500)\n",
    "    chosen_img = images[idx]\n",
    "    closest = get_closest(images, error_matrix, idx, 10)\n",
    "    images_with_median_col = add_colour_below([chosen_img] + list(closest))\n",
    "    showImages(images_with_median_col, h = chosen_img.height * 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_example()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}